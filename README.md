# Framework de ClassificaÃ§Ã£o de Incidentes de SeguranÃ§a

## ğŸ”’ VisÃ£o Geral

O **Framework de ClassificaÃ§Ã£o de Incidentes de SeguranÃ§a** Ã© uma soluÃ§Ã£o plugÃ¡vel e extensÃ­vel para classificaÃ§Ã£o automatizada de incidentes de seguranÃ§a cibernÃ©tica usando tÃ©cnicas avanÃ§adas de prompt engineering e diferentes modelos de linguagem (LLMs/SLMs).

### âœ¨ CaracterÃ­sticas Principais

- **ğŸ”Œ Arquitetura PlugÃ¡vel**: Sistema modular que permite adicionar novos modelos e tÃ©cnicas facilmente
- **ğŸ¤– MÃºltiplos Provedores**: Suporte para OpenAI, Hugging Face, Ollama e outros via LiteLLM
- **ğŸ¯ TÃ©cnicas de Prompt AvanÃ§adas**: ImplementaÃ§Ã£o de Progressive Hint, Self Hint, Progressive Rectification e Hypothesis Testing
- **ğŸ“Š ClassificaÃ§Ã£o NIST**: CategorizaÃ§Ã£o automÃ¡tica seguindo padrÃµes NIST (CAT1-CAT12)
- **ğŸ“ˆ MÃ©tricas Detalhadas**: Tracking de tokens, custos e performance
- **ğŸ”§ ConfiguraÃ§Ã£o FlexÃ­vel**: Sistema de configuraÃ§Ã£o JSON/YAML com variÃ¡veis de ambiente

## ğŸš€ InstalaÃ§Ã£o RÃ¡pida

### PrÃ©-requisitos

- Python 3.8+
- pip
- Git

### Setup Automatizado

```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd security-incident-framework

# Execute o script de setup
./create_framework.sh
```

### Setup Manual

```bash
# Crie ambiente virtual
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Instale dependÃªncias
pip install -r requirements.txt

# Configure variÃ¡veis de ambiente (opcional)
cp .env.example .env
# Edite .env com suas chaves de API
```

## ğŸ“– Uso

### Comando BÃ¡sico

```bash
python main.py data/ --columns "descricao" --model openai_gpt4 --technique progressive_hint
```

### Exemplos PrÃ¡ticos

#### 1. Usando OpenAI GPT-4 com Progressive Hint
```bash
python main.py incidents/ \
  --columns "description" "severity" \
  --model openai_gpt4 \
  --technique progressive_hint \
  --output json \
  --max-iterations 5
```

#### 2. Usando Ollama Local com Self Hint
```bash
python main.py data/ \
  --columns "incident_description" \
  --model ollama_llama3 \
  --technique self_hint \
  --temperature 0.7 \
  --output xlsx
```

#### 2.1 ExecuÃ§Ã£o protegida com verificaÃ§Ã£o automÃ¡tica (Ollama)
```bash
./scripts/run_ollama_classification.sh data/ \
  --columns "incident_description" \
  --model ollama_llama3 \
  --technique self_hint \
  --output csv
```

Esse wrapper shell:

- Verifica se o Ollama estÃ¡ instalado e instala automaticamente, se necessÃ¡rio
- Garante que o serviÃ§o `ollama serve` esteja disponÃ­vel (inicia e encerra durante o fluxo)
- Confere se o modelo solicitado jÃ¡ estÃ¡ presente; caso contrÃ¡rio, faz o download
- Remove o modelo local apÃ³s o tÃ©rmino da classificaÃ§Ã£o, evitando ocupar espaÃ§o em disco (`export OLLAMA_KEEP_MODELS=1` para manter)

#### 3. Usando Hugging Face com Hypothesis Testing
```bash
python main.py incidents/ \
  --columns "description" "type" "impact" \
  --model hf_bert \
  --technique hypothesis_testing \
  --max-tokens 512 \
  --verbose
```

### Comandos Informativos

```bash
# Listar modelos disponÃ­veis
python main.py --list-models

# Listar tÃ©cnicas disponÃ­veis
python main.py --list-techniques

# InformaÃ§Ãµes do framework
python main.py --info
```

## ğŸ”§ ConfiguraÃ§Ã£o

### Estrutura de ConfiguraÃ§Ã£o

O arquivo `config/default_config.json` define:

```json
{
  "framework": {
    "name": "Security Incident Classification Framework",
    "version": "2.0.0"
  },
  "models": {
    "openai_gpt4": {
      "plugin": "OpenAIModelPlugin",
      "provider": "openai",
      "model": "gpt-4-turbo",
      "api_key": "${OPENAI_API_KEY}",
      "temperature": 0.3
    },
    "ollama_llama3": {
      "plugin": "OllamaModelPlugin",
      "provider": "ollama",
      "model": "llama3:8b",
      "api_base": "http://localhost:11434"
    }
  },
  "prompt_techniques": {
    "progressive_hint": {
      "plugin": "ProgressiveHintPlugin",
      "default_params": {
        "max_iterations": 3,
        "rouge_threshold": 0.7
      }
    }
  }
}
```

### VariÃ¡veis de Ambiente

Crie um arquivo `.env` com suas credenciais:

```env
# OpenAI
OPENAI_API_KEY=sk-your-openai-key

# Hugging Face
HUGGINGFACE_API_TOKEN=hf_your-token

# Azure OpenAI (opcional)
AZURE_OPENAI_API_KEY=your-azure-key
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
```

## ğŸ—ï¸ Arquitetura

### Estrutura do Projeto

```
security-incident-framework/
â”œâ”€â”€ core/                    # NÃºcleo do framework
â”‚   â”œâ”€â”€ framework.py         # Classe principal
â”‚   â”œâ”€â”€ plugin_manager.py    # Gerenciador de plugins
â”‚   â””â”€â”€ config_loader.py     # Carregador de configuraÃ§Ãµes
â”œâ”€â”€ plugins/                 # Sistema de plugins
â”‚   â”œâ”€â”€ models/              # Plugins de modelos
â”‚   â”‚   â”œâ”€â”€ base_model.py    # Classe base para modelos
â”‚   â”‚   â”œâ”€â”€ openai_model.py  # Plugin OpenAI
â”‚   â”‚   â”œâ”€â”€ ollama_model.py  # Plugin Ollama
â”‚   â”‚   â””â”€â”€ huggingface_model.py # Plugin Hugging Face
â”‚   â””â”€â”€ prompts/             # Plugins de tÃ©cnicas
â”‚       â”œâ”€â”€ base_prompt.py   # Classe base para prompts
â”‚       â”œâ”€â”€ progressive_hint.py
â”‚       â”œâ”€â”€ self_hint.py
â”‚       â”œâ”€â”€ progressive_rectification.py
â”‚       â””â”€â”€ hypothesis_testing.py
â”œâ”€â”€ utils/                   # UtilitÃ¡rios
â”‚   â”œâ”€â”€ logger.py           # Sistema de logging
â”‚   â”œâ”€â”€ metrics.py          # MÃ©tricas e monitoramento
â”‚   â”œâ”€â”€ file_handlers.py    # ManipulaÃ§Ã£o de arquivos
â”‚   â””â”€â”€ security_extractor.py # ExtraÃ§Ã£o de categorias NIST
â”œâ”€â”€ config/                  # ConfiguraÃ§Ãµes
â”‚   â””â”€â”€ default_config.json  # ConfiguraÃ§Ã£o padrÃ£o
â”œâ”€â”€ data/                    # Dados de entrada
â”œâ”€â”€ output/                  # Resultados
â”œâ”€â”€ logs/                    # Arquivos de log
â””â”€â”€ main.py                  # Ponto de entrada
```

### Fluxo de ExecuÃ§Ã£o

1. **InicializaÃ§Ã£o**: Carrega configuraÃ§Ãµes e registra plugins
2. **ValidaÃ§Ã£o**: Verifica dados de entrada e parÃ¢metros
3. **Processamento**: Executa tÃ©cnica de prompt escolhida
4. **ClassificaÃ§Ã£o**: Aplica categorizaÃ§Ã£o NIST
5. **Resultados**: Salva em formato especificado
6. **MÃ©tricas**: Gera relatÃ³rio de performance

## ğŸ¯ TÃ©cnicas de Prompt

### 1. Progressive Hint Prompting (PHP)
Melhora iterativamente as respostas atravÃ©s de dicas contextuais.

**ParÃ¢metros:**
- `max_iterations`: MÃ¡ximo de iteraÃ§Ãµes (padrÃ£o: 3)
- `rouge_threshold`: Threshold para convergÃªncia (padrÃ£o: 0.7)

### 2. Self Hint Prompting (SHP)
O modelo gera suas prÃ³prias dicas para melhorar a classificaÃ§Ã£o.

**ParÃ¢metros:**
- `max_iterations`: MÃ¡ximo de iteraÃ§Ãµes (padrÃ£o: 3)

### 3. Progressive Rectification Prompting (PRP)
Corrige progressivamente erros de classificaÃ§Ã£o identificados.

**ParÃ¢metros:**
- `max_iterations`: MÃ¡ximo de iteraÃ§Ãµes (padrÃ£o: 3)
- `confidence_threshold`: Threshold de confianÃ§a (padrÃ£o: 0.8)

### 4. Hypothesis Testing Prompting (HTP)
Testa mÃºltiplas hipÃ³teses de classificaÃ§Ã£o antes da decisÃ£o final.

**ParÃ¢metros:**
- `num_hypotheses`: NÃºmero de hipÃ³teses (padrÃ£o: 3)

## ğŸ“Š Categorias NIST

O framework classifica incidentes nas seguintes categorias:

| CÃ³digo | Categoria | DescriÃ§Ã£o |
|--------|-----------|-----------|
| CAT1 | Account Compromise | Comprometimento de contas |
| CAT2 | Malware | InfecÃ§Ã£o por cÃ³digo malicioso |
| CAT3 | Denial of Service | Ataques de negaÃ§Ã£o de serviÃ§o |
| CAT4 | Data Leak | Vazamento de dados sensÃ­veis |
| CAT5 | Vulnerability Exploitation | ExploraÃ§Ã£o de vulnerabilidades |
| CAT6 | Insider Abuse | Abuso interno |
| CAT7 | Social Engineering | Engenharia social |
| CAT8 | Physical Incident | Incidentes fÃ­sicos |
| CAT9 | Unauthorized Modification | ModificaÃ§Ãµes nÃ£o autorizadas |
| CAT10 | Misuse of Resources | Uso indevido de recursos |
| CAT11 | Third-Party Issues | Problemas de terceiros |
| CAT12 | Intrusion Attempt | Tentativas de intrusÃ£o |

## ğŸ”Œ Desenvolvendo Plugins

### Plugin de Modelo

```python
from plugins.models.base_model import BaseModelPlugin

class CustomModelPlugin(BaseModelPlugin):
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        # ConfiguraÃ§Ã£o especÃ­fica
    
    def send_prompt(self, prompt: str, **kwargs) -> str:
        # ImplementaÃ§Ã£o da comunicaÃ§Ã£o com o modelo
        pass
```

### Plugin de TÃ©cnica

```python
from plugins.prompts.base_prompt import BasePromptPlugin

class CustomPromptPlugin(BasePromptPlugin):
    def execute(self, prompt: str, incident_data: pd.Series, 
                columns: List[str], **params) -> List[Dict[str, Any]]:
        # ImplementaÃ§Ã£o da tÃ©cnica
        pass
```

## ğŸ“ˆ MÃ©tricas e Monitoramento

O framework coleta automaticamente:

- **Tokens utilizados** por modelo e tÃ©cnica
- **Custos estimados** baseados em preÃ§os de API
- **Tempo de processamento** por incidente
- **Taxa de sucesso** na classificaÃ§Ã£o
- **DistribuiÃ§Ã£o de categorias** NIST

### VisualizaÃ§Ã£o de MÃ©tricas

```python
from utils.metrics import MetricsCollector

collector = MetricsCollector()
summary = collector.log_performance_summary()
print(f"Total de tokens: {summary['total_tokens']}")
print(f"Custo total: ${summary['total_cost']:.4f}")
```

## ğŸ› ï¸ Formatos Suportados

### Entrada
- **CSV**: Arquivos com delimitadores padrÃ£o
- **JSON**: Objetos e arrays
- **XLSX**: Planilhas Excel

### SaÃ­da
- **CSV**: Formato padrÃ£o para anÃ¡lise
- **JSON**: Estruturado para APIs
- **XLSX**: Para relatÃ³rios executivos

## ğŸ§ª Testes

```bash
# Executar todos os testes
python -m pytest tests/

# Testes especÃ­ficos
python -m pytest tests/test_plugins.py -v

# Testes com coverage
python -m pytest --cov=core --cov=plugins tests/
```

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

### Diretrizes de ContribuiÃ§Ã£o

- Siga PEP 8 para estilo de cÃ³digo Python
- Adicione testes para novas funcionalidades
- Atualize documentaÃ§Ã£o quando necessÃ¡rio
- Use type hints em todas as funÃ§Ãµes pÃºblicas

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ†˜ Suporte

### FAQ

**P: Como adicionar um novo provedor de LLM?**
R: Crie um plugin herdando de `BaseModelPlugin` e adicione a configuraÃ§Ã£o no arquivo de config.

**P: O framework funciona offline?**
R: Sim, usando modelos locais via Ollama.

**P: Como customizar as categorias NIST?**
R: Modifique o arquivo `utils/security_extractor.py` e atualize a configuraÃ§Ã£o.

### Contato

- **Issues**: Use o sistema de issues do GitHub
- **DocumentaÃ§Ã£o**: Wiki do projeto
- **Email**: [seu-email@exemplo.com]

## ğŸ™ Agradecimentos

- [LiteLLM](https://docs.litellm.ai/) pela interface unificada de LLMs
- [Ollama](https://ollama.ai/) por facilitar uso de SLMs locais
- Comunidade NIST pelos padrÃµes de classificaÃ§Ã£o de incidentes

---

**VersÃ£o**: 2.0.0  
**Ãšltima atualizaÃ§Ã£o**: Setembro 2025  
**Status**: ğŸŸ¢ Ativo
