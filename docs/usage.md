# Guia de Uso Completo

## Pr√©-requisitos

### Requisitos de Sistema

| Componente | Vers√£o M√≠nima | Recomendada | Observa√ß√µes |
|------------|---------------|-------------|-------------|
| **Python** | 3.8+ | 3.11+ | Necess√°rio para execu√ß√£o do framework |
| **pip** | 21.0+ | √öltima | Gerenciador de pacotes Python |
| **Sistema Operacional** | Linux/macOS/Windows | Ubuntu 22.04+ | Testado principalmente em Linux |
| **RAM** | 4GB | 8GB+ | Depende do modelo usado |
| **Armazenamento** | 2GB | 10GB+ | Para modelos locais |

### Depend√™ncias Externas (Opcionais)

| Ferramenta | Uso | Instala√ß√£o |
|------------|-----|------------|
| **Ollama** | Modelos locais | Instala√ß√£o autom√°tica via script |
| **Docker** | Containeriza√ß√£o | `docker.com` |
| **curl** | Downloads e APIs | Geralmente pr√©-instalado |
| **git** | Controle de vers√£o | `git-scm.com` |

## Instala√ß√£o

### 1. Instala√ß√£o B√°sica

#### Clone do Reposit√≥rio
```bash
# Via HTTPS
git clone https://github.com/seu-usuario/security-incident-framework.git
cd security-incident-framework

# Via SSH (se configurado)
git clone git@github.com:seu-usuario/security-incident-framework.git
cd security-incident-framework
```

#### Ambiente Virtual (Recomendado)
```bash
# Criar ambiente virtual
python3 -m venv venv

# Ativar ambiente virtual
# Linux/macOS:
source venv/bin/activate

# Windows:
# venv\Scripts\activate

# Verificar ativa√ß√£o
which python  # Deve mostrar o caminho do venv
```

#### Instalar Depend√™ncias
```bash
# Instalar depend√™ncias principais
pip install -r requirements.txt

# Verificar instala√ß√£o
python -c "import litellm, pandas, tqdm; print('Depend√™ncias OK!')"
```

### 2. Instala√ß√£o com Docker

#### Dockerfile B√°sico
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Instalar depend√™ncias do sistema
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copiar e instalar depend√™ncias Python  
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copiar c√≥digo do framework
COPY . .

# Tornar scripts execut√°veis
RUN chmod +x scripts/*.sh

EXPOSE 8000
CMD ["python", "main.py", "--help"]
```

#### Build e Execu√ß√£o
```bash
# Build da imagem
docker build -t security-framework .

# Execu√ß√£o b√°sica
docker run --rm security-framework python main.py --list-models

# Execu√ß√£o com volumes
docker run --rm \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/output:/app/output \
  security-framework \
  python main.py data/ --columns "text" --model openai_gpt35 --technique progressive_hint
```

### 3. Configura√ß√£o de APIs

#### OpenAI
```bash
# Definir API key
export OPENAI_API_KEY="sk-your-api-key-here"

# Verificar configura√ß√£o
python -c "import os; print('OpenAI configurado!' if os.getenv('OPENAI_API_KEY') else 'API key n√£o encontrada')"
```

#### HuggingFace
```bash
# Definir API key
export HUGGINGFACE_API_KEY="hf_your-token-here"

# Verificar configura√ß√£o
python -c "import os; print('HuggingFace configurado!' if os.getenv('HUGGINGFACE_API_KEY') else 'Token n√£o encontrado')"
```

#### Configura√ß√£o Persistente
```bash
# Adicionar ao .bashrc/.zshrc
echo 'export OPENAI_API_KEY="sk-your-key"' >> ~/.bashrc
echo 'export HUGGINGFACE_API_KEY="hf_your-token"' >> ~/.bashrc

# Recarregar shell
source ~/.bashrc
```

## Configura√ß√£o

### Arquivo de Configura√ß√£o Principal

O arquivo `config/default_config.json` controla todo o comportamento do framework:

```json
{
  "framework": {
    "name": "Security Incident Classification Framework",
    "version": "2.0.0",
    "description": "Framework plugin√°vel para classifica√ß√£o de incidentes"
  },
  "logging": {
    "level": "INFO",
    "log_dir": "logs",
    "enable_console": true,
    "enable_file": true
  },
  "models": {
    "openai_gpt4": {
      "plugin": "APIModel",
      "provider": "openai",
      "model": "gpt-4",
      "temperature": 0.7,
      "max_tokens": 2000,
      "api_key": "${OPENAI_API_KEY}",
      "base_url": null
    },
    "ollama_deepseek": {
      "plugin": "LocalModel", 
      "provider": "ollama",
      "model": "deepseek-r1:1.5b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://localhost:11434"
    }
  },
  "prompt_techniques": {
    "progressive_hint": {
      "plugin": "ProgressiveHintPlugin",
      "description": "Progressive Hint Prompting",
      "default_params": {
        "max_hints": 4,
        "limite_rouge": 0.9
      }
    }
  },
  "nist_categories": {
    "enabled": true,
    "categories": {
      "CAT1": {
        "name": "Account Compromise",
        "description": "unauthorized access to user or administrator accounts"
      }
      // ... outras categorias
    }
  },
  "output": {
    "formats": ["csv", "json", "xlsx"],
    "default_format": "csv",
    "include_metadata": true,
    "include_timestamps": true
  }
}
```

### Configura√ß√µes Personalizadas

#### Criar Configura√ß√£o de Produ√ß√£o
```bash
# Copiar configura√ß√£o base
cp config/default_config.json config/production.json

# Editar configura√ß√µes espec√≠ficas
vim config/production.json
```

#### Exemplo de Configura√ß√£o Customizada
```json
{
  "framework": {
    "name": "Production Security Framework",
    "version": "2.0.0"
  },
  "logging": {
    "level": "WARNING",
    "log_dir": "/var/log/security-framework",
    "enable_console": false,
    "enable_file": true
  },
  "models": {
    "production_gpt4": {
      "plugin": "APIModel",
      "provider": "openai", 
      "model": "gpt-4-turbo",
      "temperature": 0.3,
      "max_tokens": 1500,
      "api_key": "${OPENAI_PRODUCTION_KEY}",
      "rate_limit": 2.0
    }
  },
  "output": {
    "default_format": "json",
    "include_metadata": true,
    "include_timestamps": true
  },
  "performance": {
    "rate_limiting": {
      "api_models": 2.0,
      "local_models": 0.2
    },
    "memory_monitoring": true,
    "token_tracking": true
  }
}
```

## Prepara√ß√£o de Dados

### Formatos Suportados

#### CSV
```csv
id,description,severity,timestamp
1,"Suspicious login attempt from unknown IP",High,2024-01-15 10:30:00
2,"Malware detected on workstation",Critical,2024-01-15 11:45:00
3,"Failed authentication attempts",Medium,2024-01-15 12:15:00
```

#### JSON
```json
[
  {
    "id": 1,
    "description": "Suspicious login attempt from unknown IP",
    "severity": "High",
    "timestamp": "2024-01-15 10:30:00"
  },
  {
    "id": 2, 
    "description": "Malware detected on workstation",
    "severity": "Critical",
    "timestamp": "2024-01-15 11:45:00"
  }
]
```

#### Excel (XLSX)
- Suporta m√∫ltiplas abas
- Primeira linha deve conter cabe√ßalhos
- Encoding autom√°tico

### Estrutura de Dados Recomendada

#### Colunas Essenciais
| Coluna | Tipo | Obrigat√≥ria | Descri√ß√£o |
|--------|------|-------------|-----------|
| `id` | String/Integer | N√£o | Identificador √∫nico |
| `description` | String | Sim | Descri√ß√£o do incidente |
| `timestamp` | String | N√£o | Data/hora do incidente |
| `severity` | String | N√£o | Severidade (Low/Medium/High/Critical) |
| `source` | String | N√£o | Fonte do incidente |

#### Exemplo de Estrutura Completa
```csv
id,incident_title,incident_description,severity,source,timestamp,affected_systems,initial_classification
INC001,"Malware Detection","Antivirus detected malware on employee workstation",High,"Security Team","2024-01-15 10:30:00","WKS-001","Malware"
INC002,"Failed Logins","Multiple failed login attempts detected",Medium,"SIEM","2024-01-15 11:45:00","AD-SERVER","Account Compromise"
```

### Valida√ß√£o de Dados

#### Script de Valida√ß√£o
```python
# scripts/validate_data.py
import pandas as pd
import sys
from pathlib import Path

def validate_data_file(file_path):
    """Valida arquivo de dados."""
    try:
        # Carrega arquivo
        if file_path.suffix.lower() == '.csv':
            df = pd.read_csv(file_path)
        elif file_path.suffix.lower() == '.json':
            df = pd.read_json(file_path)
        elif file_path.suffix.lower() == '.xlsx':
            df = pd.read_excel(file_path)
        else:
            print(f"‚ùå Formato n√£o suportado: {file_path.suffix}")
            return False
        
        # Valida√ß√µes b√°sicas
        if df.empty:
            print(f"‚ùå Arquivo vazio: {file_path}")
            return False
            
        print(f"‚úÖ Arquivo carregado: {len(df)} linhas, {len(df.columns)} colunas")
        print(f"üìä Colunas: {list(df.columns)}")
        
        # Verifica colunas com texto
        text_columns = df.select_dtypes(include=['object']).columns
        if len(text_columns) == 0:
            print("‚ö†Ô∏è  Nenhuma coluna de texto encontrada")
            
        # Verifica valores nulos
        null_counts = df.isnull().sum()
        if null_counts.any():
            print("‚ö†Ô∏è  Valores nulos encontrados:")
            for col, count in null_counts[null_counts > 0].items():
                print(f"   {col}: {count} valores nulos")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erro ao processar {file_path}: {e}")
        return False

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Uso: python validate_data.py <arquivo_ou_diretorio>")
        sys.exit(1)
    
    path = Path(sys.argv[1])
    
    if path.is_file():
        validate_data_file(path)
    elif path.is_dir():
        for file_path in path.glob("*"):
            if file_path.suffix.lower() in ['.csv', '.json', '.xlsx']:
                print(f"\n--- Validando {file_path.name} ---")
                validate_data_file(file_path)
    else:
        print(f"‚ùå Caminho n√£o encontrado: {path}")
```

## Execu√ß√£o

### 1. Usando o Script Python Diretamente

#### Comando B√°sico
```bash
python main.py data/ \
  --columns "description" \
  --model openai_gpt35 \
  --technique progressive_hint \
  --output csv
```

#### Par√¢metros Principais

| Par√¢metro | Obrigat√≥rio | Descri√ß√£o | Exemplo |
|-----------|-------------|-----------|---------|
| `input_dir` | ‚úÖ | Diret√≥rio com dados | `data/` |
| `--columns` | ‚úÖ | Colunas para an√°lise | `"description,details"` |
| `--model` | ‚úÖ | Modelo configurado | `openai_gpt4` |
| `--technique` | ‚úÖ | T√©cnica de prompt | `progressive_hint` |
| `--output` | ‚ùå | Formato de sa√≠da | `csv` (padr√£o) |
| `--config` | ‚ùå | Arquivo de configura√ß√£o | `config/custom.json` |
| `--output-dir` | ‚ùå | Diret√≥rio de sa√≠da | `results/` |

#### Exemplos Avan√ßados

**M√∫ltiplas Colunas:**
```bash
python main.py data/ \
  --columns "incident_title,incident_description,severity" \
  --model openai_gpt4 \
  --technique self_hint \
  --output json \
  --max_iter 5
```

**Configura√ß√£o Personalizada:**
```bash
python main.py data/ \
  --columns "text" \
  --model production_gpt4 \
  --technique progressive_rectification \
  --config config/production.json \
  --output xlsx \
  --output-dir results/production/
```

**Com Par√¢metros de T√©cnica:**
```bash
python main.py data/ \
  --columns "description" \
  --model openai_gpt35 \
  --technique progressive_hint \
  --output csv \
  --max_hints 6 \
  --limite_rouge 0.95
```

### 2. Usando Scripts de Automa√ß√£o

#### Script Ollama (Recomendado para Modelos Locais)
```bash
# Execu√ß√£o b√°sica
./scripts/run_ollama_classification.sh data/ \
  --columns "description" \
  --model ollama_deepseek_15b \
  --technique progressive_hint \
  --output csv

# Com vari√°veis de ambiente
OLLAMA_KEEP_MODELS=1 PYTHON_BIN=/usr/bin/python3.11 \
./scripts/run_ollama_classification.sh data/ \
  --columns "incident_text" \
  --model ollama_mistral \
  --technique self_hint \
  --output json
```

### 3. Execu√ß√£o em Lote

#### Script de Lote Personalizado
```bash
#!/bin/bash
# scripts/batch_classification.sh

set -euo pipefail

DATA_DIR="data/incidents"
OUTPUT_BASE="results/$(date +%Y%m%d_%H%M%S)"
MODELS=("openai_gpt35" "openai_gpt4" "ollama_deepseek_15b")
TECHNIQUES=("progressive_hint" "self_hint" "progressive_rectification")

mkdir -p "${OUTPUT_BASE}"

# Matriz de execu√ß√µes
for model in "${MODELS[@]}"; do
  for technique in "${TECHNIQUES[@]}"; do
    echo "[INFO] Executando: ${model} + ${technique}"
    
    output_dir="${OUTPUT_BASE}/${model}_${technique}"
    mkdir -p "${output_dir}"
    
    if [[ "${model}" == ollama_* ]]; then
      # Usar script Ollama
      OLLAMA_KEEP_MODELS=1 ./scripts/run_ollama_classification.sh \
        "${DATA_DIR}" \
        --columns "description,severity" \
        --model "${model}" \
        --technique "${technique}" \
        --output json \
        --output-dir "${output_dir}"
    else
      # Usar execu√ß√£o direta
      python main.py "${DATA_DIR}" \
        --columns "description,severity" \
        --model "${model}" \
        --technique "${technique}" \
        --output json \
        --output-dir "${output_dir}"
    fi
    
    echo "[INFO] Conclu√≠do: ${model} + ${technique}"
    sleep 2  # Pausa entre execu√ß√µes
  done
done

echo "[INFO] Execu√ß√£o em lote conclu√≠da. Resultados em: ${OUTPUT_BASE}"
```

## Exemplos Pr√°ticos

### Exemplo 1: Classifica√ß√£o B√°sica

**Cen√°rio:** Classificar incidentes simples com OpenAI GPT-3.5

```bash
# 1. Preparar dados
cat > data/sample.csv << EOF
id,description
1,"User reported suspicious email with attachment"
2,"Multiple failed login attempts from external IP"
3,"Unauthorized access to file server detected"
4,"Malware alert triggered on workstation"
EOF

# 2. Executar classifica√ß√£o
python main.py data/ \
  --columns "description" \
  --model openai_gpt35 \
  --technique progressive_hint \
  --output csv

# 3. Verificar resultados
ls -la output/
head output/classification_results_*.csv
```

### Exemplo 2: An√°lise Comparativa

**Cen√°rio:** Comparar diferentes t√©cnicas de prompt no mesmo dataset

```bash
#!/bin/bash
# An√°lise comparativa de t√©cnicas

DATA_FILE="data/incidents_sample.csv"
OUTPUT_DIR="results/comparison_$(date +%Y%m%d)"
MODEL="openai_gpt4"

mkdir -p "${OUTPUT_DIR}"

# T√©cnicas a comparar
techniques=("progressive_hint" "self_hint" "progressive_rectification" "hypothesis_testing" "free_prompt")

for technique in "${techniques[@]}"; do
  echo "=== Testando t√©cnica: ${technique} ==="
  
  python main.py data/ \
    --columns "incident_description" \
    --model "${MODEL}" \
    --technique "${technique}" \
    --output json \
    --output-dir "${OUTPUT_DIR}/${technique}" \
    2>&1 | tee "${OUTPUT_DIR}/${technique}/execution.log"
  
  echo "T√©cnica ${technique} conclu√≠da"
  echo ""
done

# Gerar relat√≥rio comparativo
python scripts/compare_results.py "${OUTPUT_DIR}" \
  --output "${OUTPUT_DIR}/comparison_report.html"

echo "An√°lise comparativa conclu√≠da!"
echo "Relat√≥rio dispon√≠vel em: ${OUTPUT_DIR}/comparison_report.html"
```

### Exemplo 3: Pipeline de Produ√ß√£o

**Cen√°rio:** Pipeline automatizado para ambiente de produ√ß√£o

```bash
#!/bin/bash
# scripts/production_pipeline.sh

set -euo pipefail

# Configura√ß√µes
PROD_CONFIG="config/production.json"
DATA_SOURCE="/data/security_incidents"
OUTPUT_BASE="/results/production"
BACKUP_DIR="/backup/security_framework"
LOG_FILE="/var/log/security-framework/pipeline.log"

# Fun√ß√£o de log
log() {
  echo "[$(date '+%Y-%m-%d %H:%M:%S')] $*" | tee -a "${LOG_FILE}"
}

# Valida√ß√£o inicial
log "INFO: Iniciando pipeline de produ√ß√£o"

# Verificar dados de entrada
if [[ ! -d "${DATA_SOURCE}" ]]; then
  log "ERROR: Diret√≥rio de dados n√£o encontrado: ${DATA_SOURCE}"
  exit 1
fi

# Criar diret√≥rios
OUTPUT_DIR="${OUTPUT_BASE}/$(date +%Y%m%d_%H%M%S)"
mkdir -p "${OUTPUT_DIR}" "${BACKUP_DIR}"

# Backup da configura√ß√£o
cp "${PROD_CONFIG}" "${BACKUP_DIR}/config_$(date +%Y%m%d_%H%M%S).json"

# Validar dados
log "INFO: Validando dados de entrada"
python scripts/validate_data.py "${DATA_SOURCE}" >> "${LOG_FILE}" 2>&1

# Executar classifica√ß√£o principal
log "INFO: Executando classifica√ß√£o principal"
python main.py "${DATA_SOURCE}" \
  --columns "incident_description,severity,source" \
  --model production_gpt4 \
  --technique progressive_hint \
  --config "${PROD_CONFIG}" \
  --output json \
  --output-dir "${OUTPUT_DIR}/primary" \
  >> "${LOG_FILE}" 2>&1

# Executar classifica√ß√£o de backup
log "INFO: Executando classifica√ß√£o de backup"
OLLAMA_KEEP_MODELS=1 ./scripts/run_ollama_classification.sh \
  "${DATA_SOURCE}" \
  --columns "incident_description,severity,source" \
  --model ollama_deepseek_15b \
  --technique self_hint \
  --config "${PROD_CONFIG}" \
  --output json \
  --output-dir "${OUTPUT_DIR}/backup" \
  >> "${LOG_FILE}" 2>&1

# Gerar relat√≥rios
log "INFO: Gerando relat√≥rios"
python scripts/generate_report.py "${OUTPUT_DIR}" \
  --format html \
  --output "${OUTPUT_DIR}/executive_report.html" \
  >> "${LOG_FILE}" 2>&1

# Notifica√ß√£o (webhook, email, etc.)
log "INFO: Enviando notifica√ß√µes"
curl -X POST "${WEBHOOK_URL}" \
  -H "Content-Type: application/json" \
  -d "{\"status\": \"completed\", \"output_dir\": \"${OUTPUT_DIR}\"}" \
  >> "${LOG_FILE}" 2>&1

log "INFO: Pipeline de produ√ß√£o conclu√≠do com sucesso"
log "INFO: Resultados dispon√≠veis em: ${OUTPUT_DIR}"
```

### Exemplo 4: Processamento Incremental

**Cen√°rio:** Processar apenas novos incidentes desde a √∫ltima execu√ß√£o

```bash
#!/bin/bash
# scripts/incremental_processing.sh

set -euo pipefail

STATE_FILE="/var/lib/security-framework/last_processed.txt"
DATA_DIR="data/incidents"
OUTPUT_DIR="results/incremental"

# Obter timestamp da √∫ltima execu√ß√£o
if [[ -f "${STATE_FILE}" ]]; then
  LAST_PROCESSED=$(cat "${STATE_FILE}")
  echo "[INFO] √öltima execu√ß√£o: ${LAST_PROCESSED}"
else
  LAST_PROCESSED="1970-01-01 00:00:00"
  echo "[INFO] Primeira execu√ß√£o"
fi

# Encontrar arquivos novos/modificados
NEW_FILES=$(find "${DATA_DIR}" -type f \
  \( -name "*.csv" -o -name "*.json" -o -name "*.xlsx" \) \
  -newer "${STATE_FILE}" 2>/dev/null || find "${DATA_DIR}" -type f \
  \( -name "*.csv" -o -name "*.json" -o -name "*.xlsx" \))

if [[ -z "${NEW_FILES}" ]]; then
  echo "[INFO] Nenhum arquivo novo encontrado"
  exit 0
fi

echo "[INFO] Arquivos a processar:"
echo "${NEW_FILES}"

# Criar diret√≥rio tempor√°rio
TEMP_DIR=$(mktemp -d)
trap "rm -rf ${TEMP_DIR}" EXIT

# Copiar apenas arquivos novos
echo "${NEW_FILES}" | while read -r file; do
  cp "${file}" "${TEMP_DIR}/"
done

# Processar arquivos novos
python main.py "${TEMP_DIR}" \
  --columns "description,severity" \
  --model openai_gpt4 \
  --technique progressive_hint \
  --output csv \
  --output-dir "${OUTPUT_DIR}/$(date +%Y%m%d_%H%M%S)"

# Atualizar timestamp
date '+%Y-%m-%d %H:%M:%S' > "${STATE_FILE}"

echo "[INFO] Processamento incremental conclu√≠do"
```

## Interpreta√ß√£o de Resultados

### Formato de Sa√≠da CSV
```csv
informacoes_das_colunas,categoria,explicacao,confianca,tecnica,timestamp,erro
"description: Malware detected on workstation",CAT2,"This incident involves malware detection which falls under category CAT2 - Malware infection",0.95,progressive_hint,2024-01-15 14:30:22,False
"description: Failed login attempts",CAT1,"Multiple failed authentication attempts indicate potential account compromise - CAT1",0.87,progressive_hint,2024-01-15 14:30:25,False
```

### Formato de Sa√≠da JSON
```json
[
  {
    "informacoes_das_colunas": "description: Malware detected on workstation",
    "categoria": "CAT2", 
    "explicacao": "This incident involves malware detection which falls under category CAT2 - Malware infection",
    "confianca": 0.95,
    "tecnica": "progressive_hint",
    "timestamp": "2024-01-15 14:30:22",
    "erro": false,
    "metadata": {
      "modelo": "openai_gpt4",
      "tokens_entrada": 156,
      "tokens_saida": 89,
      "tempo_processamento": 2.3
    }
  }
]
```

### Categorias NIST

| C√≥digo | Nome | Descri√ß√£o | Exemplos |
|--------|------|-----------|----------|
| CAT1 | Account Compromise | Acesso n√£o autorizado a contas | Phishing, brute force, roubo de credenciais |
| CAT2 | Malware | Infec√ß√£o por c√≥digo malicioso | Ransomware, trojans, v√≠rus |
| CAT3 | Denial of Service | Indisponibilidade de sistemas | DDoS, ataques volum√©tricos |
| CAT4 | Data Leak | Vazamento de dados sens√≠veis | Exposi√ß√£o acidental, roubo de dados |
| CAT5 | Vulnerability Exploitation | Explora√ß√£o de vulnerabilidades | RCE, SQL injection, XSS |
| ... | ... | ... | ... |

### M√©tricas de Qualidade

#### Confian√ßa
- **0.0 - 0.3:** Baixa confian√ßa, revisar manualmente
- **0.3 - 0.7:** Confian√ßa moderada, valida√ß√£o recomendada  
- **0.7 - 0.9:** Alta confian√ßa, prov√°vel classifica√ß√£o correta
- **0.9 - 1.0:** Muito alta confian√ßa, classifica√ß√£o muito prov√°vel

#### Interpreta√ß√£o de Erros
```json
{
  "categoria": "ERROR",
  "explicacao": "Erro no processamento: API rate limit exceeded",
  "erro": true,
  "erro_detalhes": {
    "tipo": "RateLimitError",
    "mensagem": "Too many requests",
    "codigo": 429
  }
}
```

## Monitoramento e Logs

### Estrutura de Logs

```
logs/
‚îú‚îÄ‚îÄ framework.log              # Log principal do framework
‚îú‚îÄ‚îÄ security_incident_framework.log  # Log da classe principal
‚îú‚îÄ‚îÄ plugin_manager.log         # Log do gerenciador de plugins
‚îú‚îÄ‚îÄ metrics.log               # Log de m√©tricas
‚îî‚îÄ‚îÄ errors.log                # Log de erros espec√≠ficos
```

### Visualiza√ß√£o de Logs em Tempo Real

```bash
# Log principal
tail -f logs/framework.log

# Apenas erros
tail -f logs/framework.log | grep ERROR

# M√∫ltiplos logs
tail -f logs/*.log

# Com filtro colorido
tail -f logs/framework.log | grep --color=always -E "(ERROR|WARNING|INFO)"
```

### An√°lise de Logs

```bash
# scripts/analyze_logs.sh
#!/bin/bash

LOG_DIR="logs"
REPORT_FILE="logs/analysis_$(date +%Y%m%d_%H%M%S).txt"

echo "=== An√°lise de Logs - $(date) ===" > "${REPORT_FILE}"
echo "" >> "${REPORT_FILE}"

# Contagem de n√≠veis de log
echo "== N√≠veis de Log ==" >> "${REPORT_FILE}"
grep -h "INFO\|WARNING\|ERROR\|DEBUG" "${LOG_DIR}"/*.log | \
  sed 's/.*- \([A-Z]*\) -.*/\1/' | \
  sort | uniq -c | sort -nr >> "${REPORT_FILE}"

echo "" >> "${REPORT_FILE}"

# Erros mais frequentes
echo "== Erros Mais Frequentes ==" >> "${REPORT_FILE}"
grep -h "ERROR" "${LOG_DIR}"/*.log | \
  sed 's/.*ERROR - //' | \
  sort | uniq -c | sort -nr | head -10 >> "${REPORT_FILE}"

echo "" >> "${REPORT_FILE}"

# Atividade por hora
echo "== Atividade por Hora ==" >> "${REPORT_FILE}"
grep -h "2024-" "${LOG_DIR}"/*.log | \
  sed 's/^\([0-9-]* [0-9]*\):.*/\1/' | \
  sort | uniq -c >> "${REPORT_FILE}"

echo "An√°lise salva em: ${REPORT_FILE}"
```

Este guia completo fornece todas as informa√ß√µes necess√°rias para instalar, configurar e usar o framework efetivamente em diferentes cen√°rios, desde desenvolvimento at√© produ√ß√£o.