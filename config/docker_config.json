{
  "framework": {
    "name": "Security Incident Classification Framework",
    "version": "2.0.0",
    "description": "Framework pluginável para classificação de incidentes de segurança usando múltiplas técnicas de prompt e modelos LLM/SLM"
  },
  "logging": {
    "level": "INFO",
    "log_dir": "logs",
    "enable_console": true,
    "enable_file": true
  },
  "models": {
    "openai_gpt4": {
      "plugin": "APIModel",
      "provider": "openai",
      "model": "gpt-4",
      "temperature": 0.7,
      "max_tokens": 2000,
      "api_key": "${OPENAI_API_KEY}",
      "base_url": null
    },
    "ollama_deepseek_15b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "deepseek-r1:1.5b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_deepseek_r1_14b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "deepseek-r1:14b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_deepseek_r1_7b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "deepseek-r1:7b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_deepseek_r1_8b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "deepseek-r1:8b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_falcon3_10b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "falcon3:10b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_falcon3_1b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "falcon3:1b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_falcon3_3b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "falcon3:3b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_falcon3_7b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "falcon3:7b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_gemma2_27b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "gemma2:27b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_gemma2_2b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "gemma2:2b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_gemma2_9b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "gemma2:9b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_llama32_1b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "llama3.2:1b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_llama32_3b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "llama3.2:3b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_llama33_70b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "llama3.3:70b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_mistral_7b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "mistral:7b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_mistral_large": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "mistral-large",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_mistral_nemo": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "mistral-nemo",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_mistral_small": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "mistral-small",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_phi3_14b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "phi3:14b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_phi3_3_8b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "phi3.5:3.8b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_phi3_mini": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "phi3:mini",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_qwen2_0_5b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "qwen2:0.5b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_qwen2_1_5b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "qwen2:1.5b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_qwen2_7b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "qwen2:7b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_qwen2_5_0_5b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "qwen2.5:0.5b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_qwen2_5_14b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "qwen2.5:14b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_qwen2_5_1_5b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "qwen2.5:1.5b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_qwen2_5_32b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "qwen2.5:32b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_qwen2_5_3b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "qwen2.5:3b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    },
    "ollama_qwen2_5_7b": {
      "plugin": "LocalModel",
      "provider": "ollama",
      "model": "qwen2.5:7b",
      "temperature": 0.7,
      "max_tokens": 2000,
      "base_url": "http://ollama:11434"
    }
  },
  "prompting": {
    "progressive_hint": {
      "plugin": "ProgressiveHintPrompt",
      "description": "Técnica de prompting progressivo com dicas graduais",
      "iterations": 3,
      "hint_levels": ["basic", "intermediate", "advanced"]
    },
    "progressive_rectification": {
      "plugin": "ProgressiveRectificationPrompt", 
      "description": "Técnica de correção progressiva baseada em feedback",
      "iterations": 3,
      "rectification_strategy": "feedback_based"
    },
    "self_hint": {
      "plugin": "SelfHintPrompt",
      "description": "Técnica de auto-sugestão e reflexão",
      "reflection_steps": 2,
      "self_evaluation": true
    },
    "hypothesis_testing": {
      "plugin": "HypothesisTestingPrompt",
      "description": "Técnica baseada em teste de hipóteses",
      "hypothesis_count": 3,
      "validation_method": "elimination"
    }
  },
  "output": {
    "formats": ["json", "xlsx", "csv"],
    "include_metadata": true,
    "include_confidence": true,
    "default_format": "xlsx"
  },
  "evaluation": {
    "metrics": ["accuracy", "precision", "recall", "f1", "confusion_matrix"],
    "cross_validation": {
      "enabled": false,
      "folds": 5
    }
  }
}